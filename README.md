# Kinh-nghiem-hay

https://ongxuanhong.wordpress.com/2015/10/11/gop-nhat-kinh-nghiem-lam-nghe-data-scientist/

Dự án Data Science cần có các thành viên sau trong nhóm:
Algorithms team: những chuyên gia về thuật toán, thường có bằng Phd/Master trong lĩnh vực khoa học máy tính và thống kê, kĩ năng làm việc với R, Python, thuật toán, và Machine learning.
Big Data team: thu thập, tiền xử lý và quản trị dữ liệu Big Data (Extract, Transform, Load), chiếm 80% trong quá trình phát triển.
Domain Experts: những chuyên gia về mô hình kinh doanh, thường có bằng MBA, đảm bảo những phân tích và nghiên cứu được đưa vào sử dụng đúng với mục tiêu kinh doanh của doanh nghiệp.
Visualization and Design team: thiết kế và trình diễn mô hình dữ liệu hay dự đoán sao cho người sử dụng có thể quan sát một cách trực quan và nhanh chóng nhất để có thể đưa ra quyết định một cách hiệu quả.
Product Managers: người đảm bảo tiến độ của dự án, tập hợp và điều phối tiến trình làm việc của mọi người.

Bạn phải hiểu được ý nghĩa của tập dữ liệu muốn nói gì, điều này rất quan trọng. Đây là một nghệ thuật chứ chưa liên quan gì đến thuật toán hay kĩ thuật lập trình.
Dù có nhiều công cụ hay nhiều phương pháp đi chăng nữa, nếu bạn không biết được bài toán muốn giải và làm thế nào sử dụng tập dữ liệu hiện tại để giải quyết thì mọi thứ cũng bằng thừa.
Bạn cần biết về kĩ thuật phần mềm để có thể xây dựng được một hệ thống mang lại trải nghiệm tốt nhất tại đúng thời điểm cho người sử dụng.
Phần lớn 90% công việc của bạn là tinh chỉnh và làm sạch dữ liệu.
Cẩn trọng khi lựa chọn thu thập dữ liệu từ các nguồn: website analytics, social media data, sensor data, machine log data, media, business apps.
Công nghệ dữ liệu phân tán Hadoop/Spark được dùng để xây dựng mô hình dự đoán với tốc độ cao gần như real-time. Mô hình kết quả sẽ được lưu trữ tại cơ sở dữ liệu NoSQL như MongoDB, Cassandra cho các tác vụ truy vấn (Pig, Hive, SQL-like). Ta sẽ lên lịch cập nhật mô hình định kỳ theo ngày hay tuần.
Nên sử dụng dịch vụ cloud computing như Amazon Web Service, Databricks thay vì tốn nhiều thời gian và chi phí để mua máy móc thiết bị phục vụ cho phân tích Big Data. Mà các máy móc này thường lỗi thời rất nhanh, ta nên sử dụng dịch vụ cloud trả phí theo dung lượng sử dụng, hoặc theo sức mạnh phần cứng.
Sử dụng github, bitbucket, hay sourceforge để lưu lại các tài liệu phân tích dữ liệu của mình và chia sẻ cho cộng đồng.
Bạn không cần phải biết lập trình Java để tiếp cận với Hadoop. Ta đơn giản hóa tiến trình bằng cách sử dụng Pig hoặc Hive. Trong đó, 10 dòng code của Pig = 200 dòng code của Java.
Các dự án Kaggle không tạo nên thế mạnh cho Resume của bạn:
Bạn không có gì nổi bật trừ khi bạn đạt vị trí top 5 trong bảng xếp hạng.
Bạn không chứng minh được kĩ năng phân tích và xử lý dữ liệu của mình. Bởi vì các tập dữ liệu của Kaggle đều đã được tiền xử lý để giúp các Data scientist tập trung nhiều hơn vào xây dựng mô hình dự đoán.
Bạn không cho thấy được sáng kiến của mình trong giải quyết vấn đề thực tế. Mọi ý tưởng đều đã được Kaggle đặt ra và bạn chỉ có việc đi giải quyết các bài toán này. Trong thực tế, việc xác định được các bài toán cần giải là một bước quan trọng và tốn rất nhiều thời gian.
Hầu hết các dự án bạn bắt tay vào làm đều không liên quan đến lĩnh vực của công ty bạn muốn apply. Ví dụ, công ty bạn đang cần xây dựng hệ thống recommendation system nhưng bạn chỉ show được các dự án về xử lý ảnh y khoa.

Để bắt đầu một dự án, cách đơn giản nhất là tìm cho mình một tập dữ liệu yêu thích như Iris sau đó cố gắng trả lời các câu hỏi như làm thế nào để phân lớp các loài hoa khi chỉ biết một vài thuộc tính… Một số nguồn để download tập dữ liệu: 100+ Interesting Data Sets for Statistics, Datasets subreddit, UCI machine learning repository.
Hãy bắt đầu viết blog, post các kết quả phân tích dữ liệu mà mình đã tìm tòi tuần qua. Việc này giúp bạn thu được kĩ năng trình bày cũng như khích lệ bản thân để tiếp tục học hỏi. “If you can’t explain it simply, you don’t understand it well enough.” – Albert Einstein. Do đó, nếu bạn có thể giải thích một cách đơn giản, dễ hiểu các lý thuyết phức tạp cho mọi người thì bạn đã hiểu vấn đề đó một cách thấu đáo.
Theo dõi các blog hay trang web như kdnuggets, oreilly, datasciencecentral, insidebigdata, Quora, DataTau, machine learning subreddit, Edwin Chen, International Journal of Forecasting, UC Berkeley Social Lab, Nervana.
Thử tham gia các cuộc thi trên Kaggle để làm quen với những bài toán thực tế mà các doanh nghiệp đặt ra.
“Học thầy không tày học bạn”. Hãy lập một nhóm riêng của bạn về data science, mỗi tuần chia sẻ kiến thức và kinh nghiệm với nhau, bạn sẽ học được rất nhiều điều mới mẻ cũng như tiết kiệm nhiều thời gian tìm tòi.
Thử thách bản thân với tập dữ liệu Big data: bạn sẽ học hỏi được thêm những kiến thức cũng như các kĩ năng làm việc trên các hệ thống phân tán và sử lý song song như Hadoop, Spark, Mahout, YARN, HBase, Kudu, MapReduce, Hive, Pig, …
Trau dồi kiến thức bản thân thông qua các thuật toán machine learning tiên tiến nhất hiện nay như Deep learning, Topic modeling, Word2vec, On-line learning, …
Hãy hiểu điểm mạnh trong việc học của mình để tiếp cận data science nhanh hơn. Nếu bạn có óc tư duy lý thuyết tốt thì bạn có thể tìm đọc cùng lúc rất nhiều cuốn sách về học thuật để trau dồi kiến thức của mình. Nếu bạn là người thiên về kĩ thuật thì các tutorial step-by-step, các dự án nhỏ, hay học hỏi kinh nghiệm từ bạn bè của mình sẽ không phải là một ý kiến tồi.
Những trang web giúp bạn tiếp cận data science thông qua thực hành: Dataquest, Datacamp.
